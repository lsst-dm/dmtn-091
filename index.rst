..
========================================
Test Datasets for Performance Monitoring
========================================


Related Work
============
Also see test dataset document by Bellm, Bosch, Ivezic, Slater, and Wood-Vasey.
That document was written more toward defining datasets that can demonstrate that we pass tests in LSE-61.

This present document is written toward providing rfegular testing of KPMs and related metrics.  These are thus very related, but this present document focuses more on operational definitions.

Data Sets Types and Goals
=========================
1. CI
    * Requirements
        - Runs in 15 minutes total on 16 cores
    * Goals
        - Test that key initial processing steps execute
    * Steps
        - ISR
        - processCcd
        - ~Coadd~
        - ~DIA~
        - ~Forced Photometry~

2. Small
    * Requirements
        - 1 hour on 16-32 cores
        - Coadd at least 5 images
        - Verify that DIA works
    * Goals
        - Fuller integrated testing
        - Verify DIA runs
        - Allow checks for reasonable:
            - Numbers of stars
            - zeropoints
            - KPMs
    * Steps
        - ISR
        - processCcd
        - Coadd
        - DIA
        - Forced Photometry

3. Medium
    * Requirements
        - 8 hours on 64-128 cores
        - At least 2 filters
        - Coadd at least 5 images
    * Goals
        - Quantitative Performance, both static sky and DIA
        - Including known edge cases
        - Suitable for daily tracking of regression both in metrics and robustness.
    * Steps
        - ISR
        - processCcd
        - Coadd
        - DIA
        - Forced Photometry

4. Large
    * Goals
        - 48 hours on 512 cores
        - At least 3 filters
        - Coadd at least 5 images.
    * Goals
        - Peformance Report
        - KPMs should be suitable to predict full survey performance to ~50%
        - Generate DRP/DPDD
        - Sufficient for testing loading of data
    * Steps
        - ISR
        - processCcd
        - Coadd
        - DIA
        - Forced Photometry
        - Ingest of data into database/DPDD structure

Practical Notes
===============
Master calibration images will be required prior to processing.  We will not be testing the generation of these master calibration images as part of the processing of these datasets.

Reference catalogs will be required.

Jenkins vs. NCSA
================
The above goals and dataset definitions are written with the NCSA Verification Cluster in mind.
The current Jenkins AWS solution has a much smaller number of available cores than the NCSA Verification Cluster.  The limitations imposed by that mean that a more restricted set of minimal data will be necessary.  This more limited set of data may also be appropriate for use on an individual machine for direct developer testing.

Such a more limited set of data might be generated by selecting just the overlapping detectors from the full visit IDs.  The goal is to maintain some significant overlap area for the coadds and DIA.

Future Work
===========
1. Integrate with DM-SST document thinking
2. DIA/AP.  Consult with UW group about current thinking
3. Coordinate with CFHT experts to secure well-understood CFHT dataset.


Example Datasets
================
1. LARGE:
    * The HSC PDR that is currently processed bi-weekly satisfies needs for Large datasets
    * Modulo
      1. DIA
      2. testing of ingestion of data.

2. MEDIUM:
    a. DECam DES-SN fields.
      - 10 fields from 2014 (DES Y2) in field SN-X3.
      - g (no particular reason for this choice)
      - visits = [371412, 371413, 376667, 376668, 379288, 379289, 379290, 381528, 381529]
      - Available on lsst-dev in /datasets/des_sn

    b. DECam HiTS
      - See https://dmtn-039.lsst.io/
      - Available on lsst-dev in /datasets/decam/_internal/hits
      - Total of 2269 images available.
      - Blind15A_26, Blind15A_40, and Blind15A_42 have been selected for AP testing in
        https://github.com/lsst/ap_verify_hits2015
3. CI
    a. HSC Engineering data "ci_hsc"
      - 8 GB of data.  Runs through single-frame, coadd, and forced photometry.
      - Takes several hours when running on only a few nodes.
    b. DECam HiTS
      - A subset of data intended for CI AP testing (with Blind15A_40 and Blind15A_42) is in
        https://github.com/lsst/ap_verify_ci_hits2015

:tocdepth: 1

.. Please do not modify tocdepth; will be fixed when a new Sphinx theme is shipped.

.. sectnum::

.. TODO: Delete the note below before merging new content to the master branch.

.. note::

   **This technote is not yet published.**

   Planning out datatests for regular performance monitor of the Science Pipelines from CI through large-scale performance reports.

.. Add content here.
.. Do not include the document title (it's automatically added from metadata.yaml).

.. .. rubric:: References

.. Make in-text citations with: :cite:`bibkey`.

.. .. bibliography:: local.bib lsstbib/books.bib lsstbib/lsst.bib lsstbib/lsst-dm.bib lsstbib/refs.bib lsstbib/refs_ads.bib
..    :encoding: latex+latin
..    :style: lsst_aa
